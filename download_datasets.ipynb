{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# YOLO Face\n",
    "- These instrucitons are followed for training: https://github.com/akanametov/yolo-face?tab=readme-ov-file#training-1\n",
    "- The following code downloads the WIDER FACE dataset and places it in the correct directory from this HF dataset: https://huggingface.co/datasets/CUHK-CSE/wider_face/blob/main/data/WIDER_train.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "from huggingface_hub import hf_hub_download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_models_dir = \"dataset_folders\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolo_face_dir = os.path.join(datasets_models_dir, \"yolo_face\")\n",
    "repo_id = \"CUHK-CSE/wider_face\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zip_files = [\"WIDER_test.zip\", \"WIDER_train.zip\", \"WIDER_val.zip\", \"wider_face_split.zip\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for zip_file in zip_files:\n",
    "    # Download the zip file\n",
    "    downloaded_file_path = hf_hub_download(repo_id=repo_id, filename=os.path.join(\"data\", zip_file), repo_type=\"dataset\")\n",
    "\n",
    "    # Create a new folder in the output directory named after the zip file (without the .zip extension)\n",
    "    zip_file_base_name = os.path.splitext(zip_file)[0]\n",
    "\n",
    "    # Unzip the downloaded file into the newly created directory\n",
    "    with zipfile.ZipFile(downloaded_file_path, 'r') as zip_ref:\n",
    "        zip_ref.extractall(yolo_face_dir)\n",
    "\n",
    "    print(f\"Extracted {zip_file} to {yolo_face_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ADA Face\n",
    "\n",
    "- Follow these instruction for training: https://github.com/mk-minchul/AdaFace/blob/master/README_TRAIN.md\n",
    "- The MS1M-ArcFace dataset (MS1MV2) from InsightFace is used from training here: https://github.com/deepinsight/insightface/tree/master/recognition/\\_datasets\\_\n",
    "- Unzip the file and place the contents of `faces_emore` inside `dataset_folders/ada_face`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ViT Pose + YOLO Person\n",
    "- ViT Pose and YOLO are trained on the MS COCO keypoints dataset and the COCO dataset respectively.\n",
    "- Both of these models use the COCO API to train, so nothing needs to be downloaded."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
